{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt0AJwAMpf3W"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "import os\n",
        "env = os.environ.copy()\n",
        "env[\"OLLAMA_HOST\"] = \"0.0.0.0\"\n",
        "env[\"OLLAMA_ORIGINS\"] = \"*\"\n",
        "\n",
        "import subprocess\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"], env=env)\n",
        "\n",
        "import threading\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "\n",
        "import time\n",
        "time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gpt-oss:20b\n",
        "!curl http://localhost:11434/api/generate -d '{ \"model\": \"gpt-oss:20b\", \"prompt\": \"Who are you?\", \"stream\": false}'\n",
        "\n",
        "#curl http://n2.ckey.vn:2421/api/generate -d '{ \"model\": \"gpt-oss:20b\", \"prompt\": \"Who are you?\", \"stream\": false}'"
      ],
      "metadata": {
        "id": "hwdj40jG-xJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%xterm\n",
        "\n",
        "# TODO: Chạy lệnh dưới để tunnel ra bên ngoài CHÚ Ý: NHẤN PHẢI RỒI CHỌN COPY TRONG MENU, NẾU BẤM CTRL + C SẼ TẮT KẾT NỐI\n",
        "# ssh -p 443 -R0:localhost:11434 qr@a.pinggy.io"
      ],
      "metadata": {
        "id": "cehOgpq4TOId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thay \"http://localhost:11434\" bằng link sinh ra từ pingy.io, ví dụ nếu thấy \"http://bsqlv-34-125-123-92.a.free.pinggy.link\"\n",
        "!curl http://tytji-34-124-205-38.a.free.pinggy.link/api/generate -d '{ \"model\": \"gpt-oss:20b\", \"prompt\": \"Tell me a joke\", \"stream\": false}'"
      ],
      "metadata": {
        "id": "o8lUFntoGiNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubX4J9cF0b8_"
      },
      "outputs": [],
      "source": [
        "# Test gọi Ollama cục bộ\n",
        "%pip install ollama\n",
        "import ollama\n",
        "response = ollama.chat(model='gpt-oss:20b', messages=[\n",
        "  {\n",
        "    'role': 'user',\n",
        "    'content': 'Tell me a joke',\n",
        "  },\n",
        "])\n",
        "count = response[\"eval_count\"]\n",
        "time = response[\"eval_duration\"] / 1000000000\n",
        "avg_tokens = round(count / time, 1)\n",
        "print(f'{avg_tokens} tokens/s')\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akCVOF7Lmj2E"
      },
      "outputs": [],
      "source": [
        "# NẾU KHÔNG MUỐN DÙNG PINGGY MÀ DÙNG NGROK THÌ SAO?\n",
        "#TODO: Vào ngrok.com đăng kí một account để lấy API-KEY\n",
        "%pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from google.colab import userdata\n",
        "ngrok_api_key = userdata.get('ngrok_API_KEY_HERE')\n",
        "ngrok.set_auth_token(ngrok_api_key)\n",
        "\n",
        "# ngrok có giới hạn 1 GB/tháng\n",
        "# zrok giới hạn là 5 GB/ngày\n",
        "# https://github.com/int11/Kaggle_remote_zrok\n",
        "# https://www.kaggle.com/code/kayak0/kaggle-zrok\n",
        "\n",
        "\n",
        "port = 11434 # Mặc định Ollama chạy ở port này\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\" * ngrok tunnel {public_url} -> http://127.0.0.1:{port}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://a7f3566c1126.ngrok-free.app/api/generate -d '{ \"model\": \"gpt-oss:20b\", \"prompt\": \"Who are you?\", \"stream\": false}'"
      ],
      "metadata": {
        "id": "t2uCZUUHpBzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}\n",
        "\n",
        "@app.get('/ask')\n",
        "async def ask(question: str):\n",
        "    return {\n",
        "        'question': question,\n",
        "        'answer': \"I don't know\"\n",
        "    }\n",
        "\n",
        "import threading\n",
        "import uvicorn\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "print(\"Server started on http://0.0.0.0:8000\")\n"
      ],
      "metadata": {
        "id": "cfy8pBtGryh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:8000"
      ],
      "metadata": {
        "id": "t1lcU37dDTjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl localhost:8000/ask?question=Tell%20me%20a%20joke"
      ],
      "metadata": {
        "id": "3goouK4zxXJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill the ngrok process, closing all active tunnels\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "dJxAw5b-z91w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}